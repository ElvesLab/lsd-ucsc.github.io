+++
title = "Languages, Systems, and Data Seminar (Winter 2021)"
date = 2021-01-02T21:45:29-08:00
math = false

+++

**Time**: Fridays, noon - 1:15pm (PT) <br/>
**Location**: The Internet <br/>
**Organizers**: Lindsey Kuper and Tyler Sorensen <br />

---

The LSD Seminar meets weekly to discuss interesting topics in the areas of programming languages, systems, databases, formal methods, security, software engineering, verification, architecture, and beyond.  Our goal is to encourage interactions and discussions between students, researchers, and faculty with interests in these areas.  The seminar is open to everyone interested.  Participating students should register for the 2-credit course CSE 280O.

For winter 2021, this seminar is completely virtual and will feature a mix of internal and external speakers.

Talks will be advertised on the [lsd-group](https://groups.google.com/a/ucsc.edu/g/lsd-group/members) and [applied-pl](https://groups.google.com/g/applied-pl) mailing lists, or contact [Lindsey](https://users.soe.ucsc.edu/~lkuper/) or [Tyler](https://users.soe.ucsc.edu/~tsorensen/) for Zoom meeting details.

| Date                | Speaker                                                               | Title                                                             |
|-------              |---------                                                              |---------                                                          |
|[Jan. 8](#jan-8)     | None                                                                  | Introductions and social time                                     |
|[Jan. 15](#jan-15)   | [Kenny Foner](https://very.science/)                                  | _TBD_                                                             |
|[Jan. 22](#jan-22)   | [Naorin Hossain](https://www.cs.princeton.edu/~nhossain/)             | _TBD_                                                             |
|[Jan. 29](#jan-29)   | [Aviral Goel](http://aviral.io/)                                      | On the Design, Implementation, and Use of Laziness in R           |
|[Feb. 5](#feb-5)     | [Victor Ying](https://www.victoraying.com/)                           | Parallelizing Sequential Code with Compiler-Hardware Co-Design    |
|[Feb. 12](#feb-12)   | [Paulette Koronkevich](https://koronkevi.ch/)                         | _TBD_                                                             |
|[Feb. 19](#feb-19)   | Kamala Ramasubramanian                                                | _TBD_                                                             |
|[Feb. 26](#feb-26)   | [Prakash Murali](https://prakashmurali.bitbucket.io/)                 | _TBD_                                                             |
|[March 5](#march-5)  | Aldrin Montana                                                        | _TBD_                                                             |
|[March 12](#march-12)| Daniel Bittman                                                        | _TBD_                                                             |


# Jan. 8

Introductions and social time

# Jan. 15

**Speaker:** [Kenny Foner](https://very.science/)

**Title:** _TBD_

**Abstract:** _TBD_

**Bio:** _TBD_

# Jan. 22

**Speaker:** [Naorin Hossain](https://www.cs.princeton.edu/~nhossain/)

**Title:** _TBD_

**Abstract:** _TBD_

**Bio:** _TBD_

# Jan. 29

**Speaker:** [Aviral Goel](http://aviral.io/)

**Title:** On the Design, Implementation, and Use of Laziness in R

**Abstract:** In this talk, I will present the design and implementation of call-by-need in R, and a data-driven study of how generations of programmers have put laziness to use in their code. In our study, we analyze 16,707 R packages and observe the creation of 270.9 B promises. Our data suggest that there is little supporting evidence to assert that programmers use laziness to avoid unnecessary computation or to operate over infinite data structures. For the most part R code appears to have been written without reliance on and in many cases even knowledge of, delayed argument evaluation. The only significant exception is a small number of packages which leverage call-by-need for meta-programming. I will discuss how we intend to leverage these insights to remove laziness from R and enable non-intrusive migration of code from lazy to eager evaluation.

**Bio:** Aviral Goel is a Computer Science Ph.D. student at Northeastern University, advised by Professor Jan Vitek. He received his Bachelor's degree in Electronics and Communication Engineering from Netaji Subhas Institute of Technology, India.

He is interested in improving tools and techniques for data science applications. He is enabling R programmers to write faster and bug-free code by migrating the language from lazy-by-default to lazy-on-demand semantics. 

He is also involved in the development of a type system for R.

# Feb. 5

**Speaker:** [Victor Ying](https://www.victoraying.com/)

**Title:** Parallelizing Sequential Code with Compiler-Hardware Co-Design

**Abstract:** Today, most code still runs on expensive, power-hungry processors that prioritize single-thread performance. Speculative parallelization is an enticing approach to accelerate computation while retaining the ease of sequential programming, by launching tasks in parallel before knowing if they are independent. Unfortunately, prior speculative parallelizing compilers and architectures achieved limited speedups due to high costs of recovering from misspeculation and hardware scalability bottlenecks.

We present T4, a parallelizing compiler that executes sequential programs as trees of tiny timestamped tasks. T4 targets the recent Swarm architecture, which presents new opportunities and challenges for automatic parallelization. T4 introduces novel compiler techniques to expose parallelism aggressively across the entire program, breaking applications into tiny tasks of tens of instructions each. Task trees unfold their branches in parallel to enable high task-spawn throughput while exploiting selective aborts to recover from misspeculation cheaply. T4 exploits parallelism across function calls, loops, and loop nests; performs new transformations to reduce task spawn costs and avoid false sharing; and exploits data locality among fine-grain tasks. As a result, T4 scales several hard-to-parallelize SPEC CPU2006 benchmarks to tens of cores, where prior work attained little or no speedup.

For more information, please visit [swarm.csail.mit.edu](swarm.csail.mit.edu)

**Bio:** Victor Ying is a 5th year PhD student at MIT, advised by Daniel Sanchez. He works on parallel architectures, compilers, and programming models. Victor's recent work focuses on redesigning abstractions between hardware and software to make it as easy to exploit multicore parallelism as it is to write ordinary sequential programs. His prior work includes Boolean satisfiability solvers, scheduling machine learning workloads on hardware accelerators, and embedded and distributed systems.

# Feb. 12

**Speaker:** [Paulette Koronkevich](https://koronkevi.ch/)

**Title:** _TBD_

**Abstract:** _TBD_

**Bio:** _TBD_

# Feb. 19

**Speaker:** Kamala Ramasubramanian

**Title:** _TBD_

**Abstract:** _TBD_

**Bio:** _TBD_

# Feb. 26

**Speaker:** [Prakash Murali](https://prakashmurali.bitbucket.io/)

**Title:** _TBD_

**Abstract:** _TBD_

**Bio:** _TBD_

# March 5

**Speaker:** Aldrin Montana

**Title:** _TBD_

**Abstract:** _TBD_

**Bio:** _TBD_

# March 12

**Speaker:** Daniel Bittman

**Title:** _TBD_

**Abstract:** _TBD_

**Bio:** _TBD_

___

[Archive](../)
